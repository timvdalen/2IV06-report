%analysis and solution: mathematics/algorithms/system design

\subsection{Data structures}

We call the final generated terrain a \textbf{Map}.
A Map is a collection of \textbf{Center}s, \textbf{Corner}s and \textbf{Edge}s.
An overview of the fields these structures contain is included as an appendix ~\ref{appendix:mapdatastructures}.

\subsection{Terrain generation}

The terrain generation happens in the following stages:

\begin{enumerate}
	\item Placing points
	\item Building graph
	\item Shaping island
	\item Assigning elevations
	\item Assigning moisture and rivers
	\item Assigning biomes
\end{enumerate}

\paragraph{Placing points}

In this stage, the points that make up the center of the polygons are selected.
We currently have a selector that returns random points, one that uses poisson trials for better randomness, one that returns points that result in a hexagonal voronoi diagram and one that results in a grid-like voronoi diagram.

The selected points become the centers of the map.

Figure~\ref{fig:algo:points} shows an example of selected points.

Algorithm~\ref{alg:point} gives pseudo-code for the point selector that results in a grid-like structure.

\begin{algo*}
\begin{sourcecode}
\algorithm{SquarePointSelector($width, height, n$)}
$P = \emptyset$
\for{$i = 0; i < \sqrt{n}; i++$}
	\for{$i = 0; i < \sqrt{n}; i++$}
		$P = P \cup \left<\frac{0.5 + i}{n} width, \frac{0.5 + j}{n} height\right>$
	|
|
\return P
\qend
\end{sourcecode}
	\caption{Point selection}
	\label{alg:point}
\end{algo*}

\paragraph{Building graph}

Next, we use the selected points to build the data structures that represent the map.
We do this by constructing a Voronoi diagram (using Fortune's algorithm) and a Delaunay triangulation and creating polygons from that.

All nodes in the Voronoi diagram become corners, all edges in the Voronoi diagram, together with their dual edge in the Delaunay triangulation, are saved as edges in the map.

Pseudo-code for this can be found in Algorithm~\ref{alg:graph}

Figure~\ref{fig:algo:voronoi} shows an example of a generated Voronoi diagram, Figure~\ref{fig:algo:delaunay} gives the resulting Delaunay triangulation.

\begin{algo*}
\begin{sourcecode}
\algorithm{BuildGraph($P$)}
$V, D =$ \textsc{GenerateVoronoi}($P$)
$centers = $\textsc{MakeCenters}($P$)
\for{$e \in V,D$}
	$edge = $\{
		\textsc{GetCenter}($centers, e.delaunay0$),
		\textsc{GetCenter}($centers, e.delaunay1$),
		\textsc{MakeCorner}($e.voronoi0$),
		\textsc{MakeCorner}($e.voronoi1$)
	\}
	\textsc{SetupRelations}($edge$)
|
\return centers
\qend
\end{sourcecode}
	\caption{Graph building}
	\label{alg:graph}
\end{algo*}

\paragraph{Shaping island}

The island shape is a function that determines which of the centers in the map are part of the island and which are water.

In Figure~\ref{fig:algo:polygons}, an example island shape is shown.

Algorithm~\ref{alg:shape} gives an example of a map shaper that results in a round island.

\begin{algo*}
\begin{sourcecode}
\algorithm{RoundMapShaper($p$)}
\return $p.x^2 + p.y^2 < 1$
\qend
\end{sourcecode}
	\caption{Shaping the island}
	\label{alg:shape}
\end{algo*}

\paragraph{Assigning elevations}

In the elevations step, we first assign elevations to corners by going from the ocean inwards, increasing the elevation by 1 whenever we move to a new rank.
Then, we redistribute the elevations by sorting all corners on elevation, and evenly distributing elevations from 0 to 1 among them.
Finally, we set the elevation of each center to the average of its corners.

Figure~\ref{fig:algo:elevation} gives an example of elevations.

Algorithm~\ref{alg:elevation} gives an overview of the elevation assignment.
Pseudo-code for its components will follow.

\begin{algo*}
\begin{sourcecode}
\algorithm{AssignElevations($shaper$)}
\textsc{AssignElevationsCorner}($shaper$)
\textsc{AssignElevationsCoastAndLand}()
\textsc{AssignElevationsRedistribute}()
\textsc{AssignElevationsPolygons}()
\qend
\end{sourcecode}
	\caption{Elevation overview}
	\label{alg:elevation}
\end{algo*}

\paragraph{Assigning moisture and rivers}

First, we calculate the corner that is downslope for each corner in the map.
Then, we use this to calculate watersheds.
After that, we randomly select a number of springs on the map, where we start a river.
From each spring, we follow the watershed corners until we reach the ocean.

Then, we assign moisture to each corner based on the distance to a river or a body of water and we redistribute moisture like elevation.
Finally, we set the moisture of each center to the average of its corners.

Algorithm~\ref{alg:moisture} gives an overview of the moisture assignment.
Pseudo-code for its components will follow.

\begin{algo*}
\begin{sourcecode}
\algorithm{AssignMoisture()}
\textsc{calculateDownslopes}()
\textsc{calculateWatersheds}()
\textsc{createRivers}()
\textsc{assignCornerMoisture}()
\textsc{assignMoistureRedistribute}()
\textsc{assignPolygonMoisture}()
\qend
\end{sourcecode}
	\caption{Moisture overview}
	\label{alg:moisture}
\end{algo*}

\paragraph{Assigning biomes}

Finally, we use the moisture and elevation properties of each center to assign a biome.

Algorithm~\ref{alg:biome} gives an impression of how this could happen, the real implementation is much more detailed.

\begin{algo*}
\begin{sourcecode}
\algorithm{getBiome($center$)}
\qif{$center.ocean$}
	\return \texttt{OCEAN}
\qelse
	\qif{$center.moisture > 0.7$}
		\return \texttt{SWAMP}
	\qelse
		\qif{$center.elevation < 0.5$}
			\return \texttt{PLAINS}
		\qelse
			\return \texttt{ROCK}
		|
	|
|
\qend
\end{sourcecode}
	\caption{Biome assignment}
	\label{alg:biome}
\end{algo*}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{points}
	\caption{Selecting points}
	\label{fig:algo:points}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{voronoi}
	\caption{Building a Voronoi diagram}
	\label{fig:algo:voronoi}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{delaunay}
	\caption{Delaunay triangulation}
	\label{fig:algo:delaunay}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{polygons}
	\caption{Determining island shape}
	\label{fig:algo:polygons}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{elevation}
	\caption{Setting elevation}
	\label{fig:algo:elevation}
\end{figure}

%TODO: Similar images for the next steps

\subsection{Geometry generation}

The geometry of the map is generated preceding the visualisation phase. The maps are exported from the generator with all additional information intact to ensure their usefulness in all applications.

The surface of the islands can be generated rather straight-forward. For each center in the map data we generate as many triangles as there are borders associated with that center. Each of these triangles are formed with the center as the first vertex and the associated border's corners as the other two vertices.

\paragraph{Normal assignment}

If we simply use normals that are actually perpendicular to these triangles, the visualised terrain will look very harsh. Each face will be obviously individually distinguishable. This can be solved by assigning the same normal vector to vertices that share the same position. 
Our normal buffers can be constructed using a set of vertices and the normals will be calculated. Depending on whether or not smoothing is set to true or false normal vectors will be modified and set to the average x, y and z values of all normal vectors associated with vertices sharing the same position vector.

This 'smoothing' process takes an exponential amount of time when the number of input vectors is increased. Passing all generated triangles as one object resulted in this smooth normal calculation taking a very large amount of time when generating geometry for maps of significant size.

Fortunately we know that only a subset of generated vertices can share positions due to the fact that we know which centers are adjacent to eachother. Therefor we kept the vertices in seperate vertex buffers. In addition, we created an additional method to construct normals for a set of vertices while considering the set of vertices and associated normals that might affect what the smoothed normal values should be. This set consists of the vertices that are generated from the adjacent centers. 

\paragraph{River geometry}

To acquire more interesting geometry for our generated maps we decided to attempt to give the randomly assigned rivers a three-dimensional representation. We considered two main approaches, each with their individual challenges. Both methods basicly lower the geometric representation for any border that is part of a river and subsequently calculate a representation of the river bed depending on the river width at that point. This varying width showcases the underlying realistic representation of rivers very nicely. Simultaniously, it is the root of all problems concerning generation of a three-dimensional representation.

First off, it seemed logical to simply run through the centers as we had done previously, check which borders are part of a river and provide half of the river bed geometry based on that information. This would be the most elegant solution but it posed some problems in that there is no information on the river further up- or downstream. Figure ~\ref{riverproblem1} shows an instance where this method can run into trouble connecting river sections.

A solution to this problem and our second approach was to construct a tree of corners as nodes and river borders as edges for each of the existing rivers. Then we can start at the mouth of the river and work our way up. This way we have all the information we need to properly connect river sections of varying widths. Sadly this approach posed a new problem ~\ref{riverproblem2} which we did not previously experience due to the fact that we were processing each junction of river sections seperately. To solve this we needed elements from our first approach. 

Both approaches run into trouble ~\ref{riverproblem3} when the generated terrain contains very small cells and/or small borders. Irregular terrain can also result in the intersections of the river banks (parallels to the river edges) being very unpredictable, in our case this lead to a very spiky representation of the rivers in larger maps where there were bound to be some irregularities. The most reasonable solution to this problem was to guarantee more regular maps.

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{mismatchedriverwidth}
	\caption{When we do not consider connecting river sections the generated geometry may not connect properly}
	\label{riverproblem1}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{obsoleteintersections}
	\caption{Some small borders may need to be disregarded when deciding where the river banks should connect, this can not be done on a junction to junction basis}
	\label{riverproblem2}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{outofpolygonintersections}
	\caption{Considering the possibility that the width of the river could cover an entire polygon makes the problem infinitely more complex}
	\label{riverproblem3}
\end{figure}

\subsection{System design}

Using wxWidgets we set up a window with the necessary controls to modify parameters with which to generate maps and export them. Within this window we will be using OpenGL to visualize the generation process and provide the user with an idea of what the map might look like in the viewer application.

\subsubsection{Preview rendering}

We want to give the user a good idea of what is being generated and how this is being done. This will highlight the workings of the generation process and allow the user to intuitively judge wether he or she should adjust the parameters.

\paragraph{Shaders}

Whenever we will be rendering anything we will be using appropriate shaders. For now we will be using a pair of relatively simple vertex and fragment shaders to be extended where needed. To start with they take into account the projection, position of the camera and model matrix for whichever object is being drawn. Furthermore each vertex has an associated position, normal and color. These are more or less minimal requirements to render anything. They also consider a single light source to add some dynamics to the map preview. 

Even with these simple shaders we can observe the effect of the calculations of the fragment shader in that eventual lighting dependent output colours are determined not per vertex but per pixel. This is one of the more obvious advantages of using our custom shaders.

The vertex shader simply takes the attributes such as position, normal and color or uv coordinate, determines the position on screen and interpolates the attributes for each pixel in between the vertices. The fragment shader is where things get interesting. Below~\ref{alg:point} is an example of our initial shader configuration. Some of the constants used should be implemented as uniforms to be adjustable per object to be drawn.
 
\begin{algo*}
\begin{sourcecode}
\textit{//Light properties}
LightPosition = vec3(50,50,10)
LightColor = vec3(1,0.8f,0.8f)
LightPower = 1500.0f
 
\algorithm{fragment($fPosition, fNormal, fColor, eyeVector, lightVector, normalVector$)}
\textit{//Material properties}
DiffuseColor = color
AmbientColor = 0.1f * color
SpecularColor = vec3(0.3,0.3,0.3)
\vspace{0.2cm}
\textit{//Angle between light and face}
n = normalize($normalVector$)
l = normalize($lightVector$)
cosTheta = clamp( dot( $n, l$ )$, 0, 1 $ )
\vspace{0.2cm}
\textit{//Angle between viewer and reflected light}
E = normalize($eyeVector$);
R = reflect($-l,n$);
cosAlpha = clamp( dot( $E,R$ )$, 0, 1$ );
\vspace{0.2cm}
\textit{//Final color determined taking all factors into account}
d = length( $lightPosition - fPosition$ )
brightness = LightPower / d$^2$
\return brightness * (AmbientColor + DiffuseColor * cosTheta + SpecularColor * cosAlpha)
\vspace{0.2cm}
\qend
\end{sourcecode}
        \caption{The fragment shader's method to return the final color}
        \label{alg:frag}
\end{algo*}

\subsection{Input/output}

Since we have a separate generator and viewer, we want the generator to be able to export maps to the disk and the viewer to be able to import.

To do this, we convert the Center, Corner and Edge objects to simple \texttt{struct}s, replacing pointers with indices.
Then, we store all relationships between centers, corner and edges to pairs of indices.
We store these structs in arrays, and write them directly to the disk.

When importing, we read from the disk into these arrays and use the indices to recreate the Center, Corner and Edge objects.
